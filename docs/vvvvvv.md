上午new
下午总结
视觉核心任务及部署
https://developer.baidu.com/article/detail.html?id=5339141
YOLOv8 参数介绍
https://blog.csdn.net/2501_91798322/article/details/151716738

# 目标检测与跟踪
## 1.1 YOLOv8：实时目标检测的标杆
输入：
- 数据源类型：摄像头实时流、本地视频文件、单张图像、图像文件夹、网络视频流
- 输入图像隐含要求：（自动兼容，无需手动配置）
  - 图像格式：支持 JPG、PNG、BMP 等主流格式
  - 尺寸要求：无需手动调整分辨率，YOLOv8 会自动将输入图像缩放至训练时的尺寸（默认 640x640），同时保持宽高比，对填充区域进行归一化处理
①保持原宽高缩放，一边为640
②小于640区域，填充黑色像素（默认），补至 640x640
③归一化处理：预处理前图像像素值范围是 [0, 255]（uint8 类型），预处理后张量像素值范围变为 [0, 1]，即为像素值除以255，（float32类型）
  - “除以 255” 是为了把像素值归一化到 0–1；
  - “存成 float32” 是为了利用浮点精度、框架兼容和训练效率，而不是为了去“用光” float32 的巨大范围。

- 数据类型：自动兼容 uint8（原始图像）和 float32（归一化图像），无需手动转换
- 通道顺序：支持 RGB/BGR 格式（OpenCV 读取的 BGR 格式会自动转换为模型所需的 RGB 格式）

输出：Results 类

| 核心属性 | 数据类型 | 含义说明 | 可用场景 |
|----------|----------|----------|----------|
| result.boxes | Boxes 类对象 | 封装所有目标的边界框、类别、置信度等核心信息（检测任务核心属性） | 提取目标位置、类别、可信度 |
| result.orig_img | numpy.ndarray | 原始输入图像（未经过缩放 / 预处理的原始帧） | 可视化绘制、保存原始尺寸结果 |
| result.orig_shape | tuple | 原始图像的尺寸 (高度，宽度) | 边界框坐标还原（如需） |
| result.path | str | 输入图像 / 帧的路径（摄像头输入为 None） | 批量处理时标记帧来源 |
| result.names | dict | 类别名称映射字典（如 {0: 'person', 1: 'car'} 等） | 将类别 ID 转换为可读的类别名称 |

核心子类：boxes

边界框计算流程：
特征提取→目标判定→坐标映射
1、输入图像→多尺度特征图：
骨干网络提取图像抽象特征

```
三维张量，形状为（C, H, W）, 通道数，高度，宽度，每个元素为对应区域的图像语义/形状特征
通道数C：特征维度，YOLOv8 不同尺度特征图通道数不同（如256，512，1024），通道数越多，特征表达能力越强
尺寸 H/W：远小于原始图像（通过下采样得到，如下采样8/16/32倍数）。每个特征点对应原始图像的一个[感受野区域]
```
2、多尺度特征图→目标区域判定：
基于anchor-free预测规则，判断特征图中那些区域对应真实目标

```
由Detect 预测头实现，经过1x1 卷积层，将特征矩阵（C, H, W）转换为 概率矩阵 （P, H, W）, 其中P=4+1+N，4 是边界框回归参数，1 是目标置信度，N是分类类别。（以上为并列参数，不是直接相加）
双阈值筛选：
1、置信度筛选，过滤背景：每个特征点预测一个目标置信度（0-1），表示特征点对应区域存在目标的概率
- 做法：设定置信度阈值（YOLOv8 默认 0.25，可通过 conf 参数调整），仅保留置信度 ≥ 阈值的特征点，过滤背景区域
- 原因：比如一张图，目标区域含有背景，非目标区域也含有背景，对于目标区域而言，负样本分布在正样本中
2、概率类别筛选：确定目标类型，softmax归一化 最大值对应类别
```

3.1 目标特征区域 → 坐标矩阵（边界框）
通过坐标解码公式，将目标特征区域映射回原始图像像素坐标，生成最终目标框

3.2 目标特征区域→目标置信度、分类类别概率：
和边界框偏移量处理一致，卷积输出原始值做激活函数处理

重要参数

