## 搭建一个T
### 1、Embedding层
Embedding 层其实是一个存储固定大小的词典的嵌入向量查找表
在输入神经网络之前，我们往往会先让自然语言输入通过分词器 tokenizer，分词器的作用是把自然语言输入切分成 token 并转化成一个固定的 index，此index对应词表中向量index，对应相近语义
词表大小则往往高达数万数十万
```
- 文本 → tokenizer→ token
- token → Embedding → 词表index，语义向量
```

如果我们将词表大小设为 4，输入“我喜欢你”，那么，分词器可以将输入转化成：
```
input: 文本
output: 词表index

input: 我
output: 0

input: 喜欢
output: 1

input：你
output: 2
```

Embedding 内部其实是一个可训练的（vocab_size，embedding_dim）的权重矩阵。词表里的每一个值，都对应一行维度为 embedding_dim 的向量。
```
vocab_size 即为token 数量，
向量维度 embedding_dim 
输出：（batch_size，seq_len，embedding_dim）批处理的数量，自然语言序列的长度，词表尺寸
```

- Embedding 本身是可学习层，
  - 以随机值初始化权重矩阵（正态分布/均匀分布）
  - 和transformer、预测头一起训练
直接使用 torch 中的 Embedding 层：
```
self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)
```
- 加载预训练权重+可选冻结
```
# 1. 先加载预训练的嵌入权重（假设pretrained_embeds是从预训练模型中读取的权重，形状[30522, 768]） 
pretrained_embeds = torch.randn(args.vocab_size, args.dim)  

# 模拟预训练权重# 2. 初始化嵌入层并加载预训练权重 
model.tok_embeddings = nn.Embedding.from_pretrained(pretrained_embeds,freeze=False  # False=继续训练，True=冻结权重不训练)

# 验证：查看是否可训练
print(f"嵌入层是否可训练

```



### 2、位置编码

注意力机制可以实现良好的并行计算，但同时，注意力机制也导致位置信息的丢失。在LSTM、RNN中，输出序列均按照文本顺序依次递归处理。

## 预训练语言模型

### BERT
BERT，全名为 Bidirectional Encoder Representations from Transformers 双向编码器表征
是由 Google 团队在 2018年发布的预训练语言模型。
Transformer 架构
预训练+微调范式

#### 模型架构 - Encoder only

延续：多个encoder堆积

改进：
BERT 是针对于 NLU 任务打造的预训练模型，其输入一般是文本序列，而输出一般是 Label，例如情感分类的积极、消极 Label。
```
NLU Natural Language Understanding 自然语言理解 
核心目标：让机器真正理解人类自然语言的语义、意图、逻辑和上下文含义
文本 → 机器理解

NLG Natural Language Generation 自然语言生成
文本 → 机器 文本输出
```

但是，正如 Transformer 是一个 Seq2Seq 模型，使用 Encoder 堆叠而成的 BERT 本质上也是一个 Seq2Seq 模型，只是没有加入对特定任务的 Decoder，

因此，为适配各种 NLU 任务，在模型的最顶层加入了一个分类头 prediction_heads，用于将多维度的隐藏状态通过线性层转换到分类维度（例如，如果一共有两个类别，prediction_heads 输出的就是两维向量）。



Encoder 块中是堆叠起来的 N 层 Encoder Layer，BERT 有两种规模的模型：
base 版本（12层 Encoder Layer，768 的隐藏层维度，总参数量 110M）
large 版本（24层 Encoder Layer，1024 的隐藏层维度，总参数量 340M）
```
在 BERT（以及所有 Transformer 架构）里，“隐藏层维度”就是：
每个 token 经过 Encoder Layer 之后，得到的向量长度——固定为 768 维（base）或 1024 维（large）
隐藏层维度 = 模型内部“词向量”的宽度，也是多头注意力里 Q/K/V 的维度，也是Feed-Forward 的输入/输出维度（FFN 中间会先放大再缩回）
```

##### 创新
每个encoder层中，immediate层，BERT特殊称呼，位于hidden_states输出之前

结构如下：
<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/3-figures/1-3.png" alt="图片描述" width="40%"/>
  <p>图3.5 Intermediate 结构</p>
</div>

1、激活函数使用的是GELU, 自 BERT 才开始被普遍关注的激活函数
$$GELU(x) = 0.5x(1 + tanh(\sqrt{\frac{2}{\pi}})(x + 0.044715x^3))$$

核心思想：引入随机正则的思想，根据输入自身的概率分布，决定此神经元是否丢弃或保留

2、BERT 将相对位置编码融合在了注意力机制中，将相对位置编码同样视为可训练的权重参数,完成注意力分数的计算之后，先通过 Position Embedding 层来融入相对位置信息：
Transformer 使用的绝对位置编码 Sinusoidal 能够拟合更丰富的相对位置信息，
但是，这样也增加了不少模型参数，同时完全无法处理超过模型训练长度的输入（例如，对 BERT 而言能处理的最大上下文长度是 512 个 token）

#### 预训练任务-MLM+NSP
MLM masked language model 掩码语言模型

LM 预训练的缺陷是拟合从左到右的语义，但忽略了双向语义（上下文）。
虽然 Transformer 中通过位置编码表征了文本序列中的位置信息，但这和直接拟合双向语义关系还是有本质区别。例如，BiLSTM（双向 LSTM 模型）在语义表征上就往往优于 LSTM 模型，就是因为 BiLSTM 通过双向的 LSTM 拟合了双向语义关系。

MLM 相较于模拟人类写作的 LM，MLM 模拟的是“完形填空”。通过mask一些token，让模型根据token上下文预测token,既利用了海量的数据进行无监督学习，同时强化了双向语义理解。

计算过程：
1. 随机把输入句子中的部分 token 换成 [MASK]；
2. 让模型只凭上下文去预测这些被盖住的 token 本身；
3. 用“原 token”作为真值计算交叉熵损失，判断预测是否准确。

```
输入：I <MASK> you because you are <MASK>
输出：<MASK> - love; <MASK> - wonderful
```

这种方式无需人为标注，只需对文本进行随机掩码，因此也可以利用互联网所有文本语料实现预训练。例如，BERT 的预训练就使用了足足 3300M 单词的语料。
“3300M 单词”里的 M 是“million”（百万）的意思，3300M = 3.3 billion 个 word piece（BERT 用的 WordPiece 子词）。
它纯粹是计数单位，跟“字节/存储大小”无关。token可以是子词，但token不一定是子词类型。

引入的策略： MLM 训练时，会随机选择训练语料中 15% 的 token 用于遮蔽；
但是这 15% 的 token 并非全部被遮蔽为 <MASK>，而是有 80% 的概率被遮蔽，10% 的概率被替换为任意一个 token，还有 10% 的概率保持不变

MLM缺陷：
LM 其训练和下游任务是完全一致的，也就是说，训练时是根据上文预测下文，下游任务微调和推理时也同样如此
MLM 缺陷：在下游任务微调和推理时，其实是不存在我们人工加入的 <MASK> 的，我们会直接通过原文本得到对应的隐藏状态再根据下游任务进入分类器或其他组件
预训练和微调的不一致，会极大程度影响模型在下游任务微调的性能


**NSP next sentence prediction 下一句预测**
针对句级的NLU，同样，也可以从海量数据中选取连续的句子作为正样本进行无监督训练。
例如问答匹配、自然语言推理等。问答匹配是指，输入一个问题和若干个回答，要求模型找出问题的真正回答；自然语言推理是指，输入一个前提和一个推理，判断推理是否是符合前提的。这样的任务都需要模型在句级去拟合关系，判断两个句子之间的关系，而不仅是 MLM 在 token 级拟合的语义关系。因此，BERT 提出了 NSP 任务来训练模型在句级的语义关系拟合。

NSP 任务的核心思路是要求模型判断一个句对的两个句子是否是连续的上下文。例如，输入和输入可以是：
```
    输入：
        Sentence A：I love you.
        Sentence B: Because you are wonderful.
    输出：
        1（是连续上下文）

    输入：
        Sentence A：I love you.
        Sentence B: Because today's dinner is so nice.
    输出：
        0（不是连续上下文）
```
同样，也可以从海量数据中选取连续的句子作为正样本进行无监督训练。


**问答匹配：**
 1 个问题（Question） 和 N 个候选回答（Candidate Answers）
```
 N 个候选回答（Candidate Answers）来源
结构化知识库（智能座舱首选）
构建方式
1、人工梳理高频问题：整理座舱用户的常见问题（Q）和标准答案（A），形成一对一 / 一对多的 QA 对
    问题（Q）	标准回答（A）	所属模块
    怎么开自动空调？	按下空调面板 AUTO 键，或语音说 “打开自动空调”	空调控制
    座椅加热怎么调最高？	长按座椅加热键 3 秒，或语音说 “座椅加热调最高”	座椅控制
2、结构化存储：将 QA 对存入数据库（如 MySQL、Redis），并按功能模块、关键词做索引，方便快速检索。
候选回答筛选逻辑
用户提问后，先通过关键词匹配 / 语义检索从知识库中筛选出与问题相关的 QA 对，得到候选回答列表：
例：用户问 “自动空调怎么开启？”→ 检索到含 “自动空调”“开启” 关键词的 QA 对 → 候选回答只有 1 个（精准匹配）；
例：用户问 “空调怎么调？”→ 检索到含 “空调” 的所有 QA 对 → 候选回答列表包含 “开自动空调”“调温度”“调风向” 等多个回答。
优势：回答准确率高、可控性强，完全适配车载场景的标准化需求；
缺点：覆盖范围有限，无法应对小众 / 个性化问题。

2. 非结构化文档抽取（补充来源）
针对知识库未覆盖的问题，候选回答可从非结构化文档中抽取，适合解决复杂、长尾的问题（如车载系统故障排查、功能说明等）。
文档来源：车载说明书、故障排查手册、功能白皮书等文本；
实现方式
文档预处理：将文档拆分为段落 / 句子级别的文本片段，每个片段作为一个 “候选回答单元”；
语义索引构建：用 BERT 等模型将每个文本片段转化为语义向量，存入向量数据库（如 FAISS、Milvus）；
候选筛选：用户提问后，将问题也转化为语义向量，在向量数据库中做相似度检索，取相似度最高的 Top-N 个文本片段作为候选回答。
示例：用户问 “空调报错 E1 怎么办？”→ 问题向量与故障手册中的 “E1 故障对应传感器异常，重启空调即可” 片段向量相似度最高 → 该片段成为候选回答。
优势：覆盖长尾问题，无需人工逐条梳理 QA 对；
缺点：回答质量依赖文档质量，可能存在冗余信息。

3. 动态生成（进阶方案，结合生成式模型）
在部分高端座舱场景中，候选回答可由大模型动态生成，再结合匹配模型做筛选，适合应对开放性问题。
实现方式
用车载轻量化大模型（如 Llama-2 量化版、Qwen-7B-int4），基于用户问题生成多个候选回答；
用问答匹配模型对生成的候选回答做质量打分，筛选出与问题最匹配、最符合车载规范的回答。
示例：用户问 “怎么快速降温？”→ 大模型生成 3 个候选回答 → 匹配模型打分后，选 “开窗通风 1 分钟后关闭，再开空调制冷模式” 作为最优回答。
优势：覆盖开放性问题，灵活性高；
缺点：对车载算力要求高，需做严格的输出控制（避免生成违规内容）。

4. 用户行为日志挖掘（冷启动 / 迭代优化）
这是补充和优化知识库的来源，通过分析用户的历史对话日志，挖掘新的问题和对应的优质回答。
实现方式
收集座舱用户的真实对话（如用户问 “空调怎么除雾？”，人工客服回复 “开前挡风除雾键”）；
定期整理这些日志，将新的 QA 对加入结构化知识库，扩充候选回答的覆盖范围。

```

**自然语言推理**
 1 个前提（Premise, P） 和 1 个假设（Hypothesis, H），模型需要判断两者的逻辑关系，通常分为三类：

 ```
关系类型	定义	示例
蕴含（Entailment）	假设 H 的内容完全由前提 P 推导得出	P：座舱温度已调至 25℃；H：当前车内温度是 25℃
矛盾（Contradiction）	假设 H 的内容与前提 P 完全相反	P：座舱温度已调至 25℃；H：当前车内温度是 30℃
中立（Neutral）	假设 H 的内容与前提 P 无必然逻辑关系	P：座舱温度已调至 25℃；H：座椅加热已开启

智能座舱场景示例：
前提 P：用户设置座舱温度为 22℃，且当前车内温度为 25℃
假设 H1：空调会自动启动制冷模式 → 蕴含关系
假设 H2：空调会自动启动制热模式 → 矛盾关系
假设 H3：氛围灯颜色为蓝色 → 中立关系

```

NSP 训练让模型能区分 “连贯句对” 和 “不连贯句对”；
NLI 任务则要求模型在 “连贯” 的基础上，进一步区分 **“蕴含”“矛盾”“中立”** 三种**更细粒度的逻辑关系**

输入序列（以 H1 为例）：
[CLS] 用户 设置 座舱 温度 为 22℃ ， 且 当前 车内 温度 为 25℃ [SEP] 空调 会 自动 启动 制冷 模式 [SEP]
（2）模型微调：三分类预测头
特征提取：同样取 BERT 输出的 [CLS] 向量 —— 该向量聚合了前提和假设的句间逻辑关系。
预测头设计：在 [CLS] 向量后接全连接层 + Softmax，输出 3 分类概率（蕴含、矛盾、中立的概率）。
分类头的损失函数：交叉熵损失（Cross-Entropy Loss）。
（3）输出结果
输出假设相对于前提的逻辑关系标签，以及对应的概率值。
示例输出：H1 → 蕴含（概率 0.98）


